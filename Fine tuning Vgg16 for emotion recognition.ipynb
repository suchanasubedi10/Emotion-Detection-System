{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25af233-08f3-4008-86b9-303e7df1f483",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b28bb0-cb3b-408d-9dc2-f46718625b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications import VGG16 #use pre-trained neural network\n",
    "from tensorflow.keras.models import Sequential #it is used to stack layers linearly\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout#imports used layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #used for data augmentation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau #regularization\n",
    "from tensorflow.keras.utils import get_file#downloading cache file\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a8c65-918e-4c6d-b4ae-3f5cdc326b1b",
   "metadata": {},
   "source": [
    "# Count the number of files contained in each subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da290454-0c3a-4e23-8d08-3933391b0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_files_in_subdirs(directory, set_name):\n",
    "    counts = {}\n",
    "\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item) #facilitate checking whether the project is a file or a subdirectories\n",
    "\n",
    "        if os.path.isdir(item_path):\n",
    "            counts[item] = len(os.listdir(item_path))\n",
    "\n",
    "    df = pd.DataFrame(counts, index=[set_name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756c0ba-d27b-481c-938d-5f9b88b1d014",
   "metadata": {},
   "source": [
    " # Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a94e41-1730-4d9b-b9c2-05cf771378b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       angry  disgust  fear  happy  neutral   sad  surprise\n",
      "train   3995      436  4097   7215     4965  4830      3171\n",
      "      angry  disgust  fear  happy  neutral   sad  surprise\n",
      "test    958      111  1024   1774     1233  1247       831\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "train_dir = 'C:/Users/shahi/OneDrive/Documents/6th sem/Minor project/Code/Try 2/tuning/Dataset/train'\n",
    "test_dir = 'C:/Users/shahi/OneDrive/Documents/6th sem/Minor project/Code/Try 2/tuning/Dataset/test'\n",
    "\n",
    "#count the files in the subdirectories of the training directory\n",
    "train_count = count_files_in_subdirs(train_dir, 'train')\n",
    "print(train_count)\n",
    "\n",
    "#count the files in the subdirectories of the testing directory\n",
    "test_count = count_files_in_subdirs(test_dir, 'test')\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbbd0f3-6b04-4bd5-8242-3457647d1cff",
   "metadata": {},
   "source": [
    " # Load Pre-Trained VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bc15c5-36fc-43bd-bb11-37f3dc9a038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pre-trained VGG16 model without the top layer\n",
    "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1b4cd5-1c96-4c3e-8082-12fd0cb19621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze all layers except the last 4 layers\n",
    "for layer in vgg16_base.layers[:8]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg16_base.layers[8:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc3cd1-14ad-48fb-9b71-0df6e6c1a0ec",
   "metadata": {},
   "source": [
    "# Add Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7c1ca2-3fc5-4161-94e9-d1ec6ad1ad6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │      \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │         \u001b[38;5;34m525,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m1,799\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,897,927</span> (60.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,897,927\u001b[0m (60.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,342,599</span> (58.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,342,599\u001b[0m (58.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">555,328</span> (2.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m555,328\u001b[0m (2.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#build the model\n",
    "#8 layers for feature extraction & several dense layers for classification\n",
    "model = Sequential()\n",
    "\n",
    "model.add(vgg16_base)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))  # Increased neurons\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))  # Reduced dropout\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31760cc0-4d54-4fa0-a506-43da1621a499",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5696a90c-b417-4611-8c95-132098adbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df0368-0e66-4abd-83a3-91c866b6e12b",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48b531-4480-4261-affe-703148b5f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ImageDataGenerator is used to apply various augmentation techniques to the training data,\n",
    "#enhancing the model's generalization ability\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3]\n",
    ")\n",
    "#Only pixel value rescaling is performed to ensure a fair evaluation of the model's performance.\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3914e5e-0b3b-4c9c-802b-ed61e18fe83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#automatically infer class labels from the directory structure, loads images, and performs necessary preprocessing\n",
    "#The generator can provide an efficient and scalable data flow during model training, helping to improve the model's generalization ability.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cbd70a2-6874-4566-9d8e-89c7ee5c98f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#automatically infer class labels from the directory structure and evaluates the model's performance at the end of each training epoch\n",
    "#The generator provides an efficient and scalable data flow for model validation, helping to monitor the model's performance on unseen data and improve its generalization ability.\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90292600-68a9-4003-8988-fde52e2bd340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class labels: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "Validation class labels: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "#show the labels of training and validation class\n",
    "train_class_labels = train_generator.class_indices\n",
    "print(\"Training class labels:\", train_class_labels)\n",
    "\n",
    "validation_class_labels = val_generator.class_indices\n",
    "print(\"Validation class labels:\", validation_class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d146f623-4bac-4b4a-9501-b63ff63a70b7",
   "metadata": {},
   "source": [
    "# Optimization technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86ffdc6-7acf-4db0-b7bd-1eaa4dce01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monitor the validation accuracy\n",
    "#prevent the model from overfittng\n",
    "#stops training at the appropriate time while restoring the best model weights\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afd4cf12-aed9-4a1c-a860-7f6215c93b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monitor the validation loss and automatically reduces the learning rate when the loss no longer improves\n",
    "#help the model find a better optimization path and ensure the effectiveness of the training process\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5dd6d-2f7f-4783-ae5c-34ed6c36857b",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6285aa9-a6ed-4c6f-b7ed-ae870fb76d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2234 - loss: 1.8506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1762s\u001b[0m 2s/step - accuracy: 0.2234 - loss: 1.8506 - val_accuracy: 0.3419 - val_loss: 1.5750 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1872s\u001b[0m 2s/step - accuracy: 0.3347 - loss: 1.6473 - val_accuracy: 0.4519 - val_loss: 1.3912 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1765s\u001b[0m 2s/step - accuracy: 0.4094 - loss: 1.5096 - val_accuracy: 0.4558 - val_loss: 1.3670 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1851s\u001b[0m 2s/step - accuracy: 0.4368 - loss: 1.4513 - val_accuracy: 0.5184 - val_loss: 1.2329 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1029s\u001b[0m 1s/step - accuracy: 0.4790 - loss: 1.3697 - val_accuracy: 0.5311 - val_loss: 1.2133 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 877ms/step - accuracy: 0.4940 - loss: 1.3438 - val_accuracy: 0.5302 - val_loss: 1.2146 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m768s\u001b[0m 855ms/step - accuracy: 0.5006 - loss: 1.3092 - val_accuracy: 0.5580 - val_loss: 1.1556 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 841ms/step - accuracy: 0.5149 - loss: 1.2922 - val_accuracy: 0.5553 - val_loss: 1.1565 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1047s\u001b[0m 1s/step - accuracy: 0.5245 - loss: 1.2676 - val_accuracy: 0.5502 - val_loss: 1.1649 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1805s\u001b[0m 2s/step - accuracy: 0.5284 - loss: 1.2529 - val_accuracy: 0.5708 - val_loss: 1.1185 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 891ms/step - accuracy: 0.5429 - loss: 1.2326 - val_accuracy: 0.5587 - val_loss: 1.1374 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m820s\u001b[0m 913ms/step - accuracy: 0.5425 - loss: 1.2223 - val_accuracy: 0.5587 - val_loss: 1.1511 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m815s\u001b[0m 907ms/step - accuracy: 0.5447 - loss: 1.2172 - val_accuracy: 0.5787 - val_loss: 1.0958 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 917ms/step - accuracy: 0.5570 - loss: 1.1945 - val_accuracy: 0.5900 - val_loss: 1.0680 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 906ms/step - accuracy: 0.5502 - loss: 1.1918 - val_accuracy: 0.5991 - val_loss: 1.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 921ms/step - accuracy: 0.5597 - loss: 1.1689 - val_accuracy: 0.6073 - val_loss: 1.0591 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 925ms/step - accuracy: 0.5691 - loss: 1.1583 - val_accuracy: 0.6038 - val_loss: 1.0436 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 921ms/step - accuracy: 0.5686 - loss: 1.1515 - val_accuracy: 0.6031 - val_loss: 1.0455 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 896ms/step - accuracy: 0.5770 - loss: 1.1367 - val_accuracy: 0.6113 - val_loss: 1.0183 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1354s\u001b[0m 2s/step - accuracy: 0.5899 - loss: 1.1261 - val_accuracy: 0.6226 - val_loss: 1.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m880s\u001b[0m 980ms/step - accuracy: 0.5892 - loss: 1.1101 - val_accuracy: 0.6052 - val_loss: 1.0554 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 957ms/step - accuracy: 0.5885 - loss: 1.1148 - val_accuracy: 0.6230 - val_loss: 1.0084 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m845s\u001b[0m 940ms/step - accuracy: 0.5944 - loss: 1.1031 - val_accuracy: 0.6186 - val_loss: 0.9943 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m815s\u001b[0m 908ms/step - accuracy: 0.5910 - loss: 1.1044 - val_accuracy: 0.6163 - val_loss: 1.0150 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 821ms/step - accuracy: 0.5936 - loss: 1.0918 - val_accuracy: 0.6266 - val_loss: 0.9897 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m734s\u001b[0m 818ms/step - accuracy: 0.5961 - loss: 1.0839 - val_accuracy: 0.6020 - val_loss: 1.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 831ms/step - accuracy: 0.6035 - loss: 1.0815 - val_accuracy: 0.6369 - val_loss: 0.9955 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m809s\u001b[0m 900ms/step - accuracy: 0.6019 - loss: 1.0742 - val_accuracy: 0.6287 - val_loss: 0.9984 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1432s\u001b[0m 2s/step - accuracy: 0.6091 - loss: 1.0509 - val_accuracy: 0.6357 - val_loss: 0.9810 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2309s\u001b[0m 3s/step - accuracy: 0.6099 - loss: 1.0530 - val_accuracy: 0.6330 - val_loss: 0.9846 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m776s\u001b[0m 864ms/step - accuracy: 0.6107 - loss: 1.0429 - val_accuracy: 0.6177 - val_loss: 1.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 956ms/step - accuracy: 0.6112 - loss: 1.0433 - val_accuracy: 0.6212 - val_loss: 0.9970 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 961ms/step - accuracy: 0.6164 - loss: 1.0351 - val_accuracy: 0.6397 - val_loss: 0.9710 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m959s\u001b[0m 1s/step - accuracy: 0.6211 - loss: 1.0307 - val_accuracy: 0.6322 - val_loss: 0.9946 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 825ms/step - accuracy: 0.6311 - loss: 1.0094 - val_accuracy: 0.6434 - val_loss: 0.9637 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 664ms/step - accuracy: 0.6233 - loss: 1.0173 - val_accuracy: 0.6449 - val_loss: 0.9544 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 692ms/step - accuracy: 0.6248 - loss: 1.0073 - val_accuracy: 0.6413 - val_loss: 0.9862 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 730ms/step - accuracy: 0.6269 - loss: 1.0065 - val_accuracy: 0.6443 - val_loss: 0.9830 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 691ms/step - accuracy: 0.6290 - loss: 0.9997 - val_accuracy: 0.6439 - val_loss: 0.9492 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 647ms/step - accuracy: 0.6325 - loss: 0.9934 - val_accuracy: 0.6291 - val_loss: 1.0056 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m677s\u001b[0m 754ms/step - accuracy: 0.6329 - loss: 0.9866 - val_accuracy: 0.6344 - val_loss: 1.0019 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 767ms/step - accuracy: 0.6386 - loss: 0.9811 - val_accuracy: 0.6507 - val_loss: 0.9546 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 992ms/step - accuracy: 0.6448 - loss: 0.9737 - val_accuracy: 0.6367 - val_loss: 0.9963 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m880s\u001b[0m 980ms/step - accuracy: 0.6409 - loss: 0.9759 - val_accuracy: 0.6496 - val_loss: 0.9804 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m885s\u001b[0m 985ms/step - accuracy: 0.6548 - loss: 0.9298 - val_accuracy: 0.6574 - val_loss: 0.9601 - learning_rate: 5.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m878s\u001b[0m 978ms/step - accuracy: 0.6603 - loss: 0.9166 - val_accuracy: 0.6555 - val_loss: 0.9700 - learning_rate: 5.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 971ms/step - accuracy: 0.6619 - loss: 0.9150 - val_accuracy: 0.6551 - val_loss: 0.9730 - learning_rate: 5.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m911s\u001b[0m 1s/step - accuracy: 0.6661 - loss: 0.9052 - val_accuracy: 0.6573 - val_loss: 0.9730 - learning_rate: 5.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m903s\u001b[0m 1s/step - accuracy: 0.6714 - loss: 0.8930 - val_accuracy: 0.6605 - val_loss: 0.9555 - learning_rate: 5.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m895s\u001b[0m 996ms/step - accuracy: 0.6783 - loss: 0.8745 - val_accuracy: 0.6601 - val_loss: 0.9762 - learning_rate: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "#train the model on training and validation dataset\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546dc728-bb58-46d7-92a1-4b4363a3f348",
   "metadata": {},
   "source": [
    "# Working with test data and evaluating test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdca0645-ae4d-48aa-b90e-8a4988653fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(48, 48),  # Replace with your model's input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48527306-7b78-42d6-812c-c2670ae5bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 - 80s - 357ms/step - accuracy: 0.6605 - loss: 0.9555\n",
      "Test Accuracy: 66.05%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e64b4-c870-40ef-a1fb-c597f40730cd",
   "metadata": {},
   "source": [
    "# Save your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce0e4005-9ee7-493b-9a3b-e7b8260a2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save('emotion_recognition_model.h5')\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd161d-f140-485f-bfd0-cc1e76e3935a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
